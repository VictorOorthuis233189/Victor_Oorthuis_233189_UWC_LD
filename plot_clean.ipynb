{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d083b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: annotated_1.png\n",
      "Saved: annotated_20.png\n",
      "Saved: annotated_29.png\n",
      "Saved: annotated_56.png\n",
      "Saved: annotated_77.png\n",
      "\n",
      "All images saved to 'PKU Dataset Annotated - Fixed' folder\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\Users\\victo\\Documents\\GitHub\\2025-26ab-fai3-specialisation-project-team-uwc-landmark-detection\\PKU_Dataset_Corrected\\image\"\n",
    "annotation_dir = r\"C:\\Users\\victo\\Documents\\GitHub\\2025-26ab-fai3-specialisation-project-team-uwc-landmark-detection\\PKU_Dataset_Corrected\\doctor1\"\n",
    "output_dir = \"PKU Dataset Annotated - Fixed\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Images to process\n",
    "images = [1, 20, 29, 56, 77]\n",
    "\n",
    "for img_num in images:\n",
    "    # Load image and annotations\n",
    "    img = Image.open(f\"{image_dir}\\\\{img_num}.bmp\")\n",
    "    with open(f\"{annotation_dir}\\\\{img_num}.json\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Image {img_num}\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Plot landmarks\n",
    "    for landmark in data['landmarks']:\n",
    "        x, y = landmark['value']['x'], landmark['value']['y']\n",
    "        ax.plot(x, y, 'r.', markersize=4)\n",
    "        ax.text(x+10, y-10, landmark['symbol'], color='yellow', \n",
    "                fontsize=7, weight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.7))\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(f\"{output_dir}\\\\annotated_{img_num}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved: annotated_{img_num}.png\")\n",
    "\n",
    "print(f\"\\nAll images saved to '{output_dir}' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adca741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: cks2ip8g62b6r0yuf65bga4sa.png\n",
      "Saved: annotated_cks2ip8g62b6r0yuf65bga4sa.png\n",
      "Processing: cl5lg05ue018y074kdq6yc9cj.jpg\n",
      "Saved: annotated_cl5lg05ue018y074kdq6yc9cj.png\n",
      "Processing: cl5lg05ur01lu074kexxr1ofb.jpg\n",
      "Saved: annotated_cl5lg05ur01lu074kexxr1ofb.png\n",
      "Processing: cl6cc2n5i401f0771as4t0pmi.jpeg\n",
      "Saved: annotated_cl6cc2n5i401f0771as4t0pmi.png\n",
      "Processing: cl7wxu5n5agfg077naial22ae.bmp\n",
      "Saved: annotated_cl7wxu5n5agfg077naial22ae.png\n",
      "\n",
      "All images saved to 'Aariz Dataset Annotated' folder\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\Users\\victo\\Downloads\\Aariz (1)\\Aariz\\Cephalograms\"\n",
    "annotation_dir = r\"C:\\Users\\victo\\Downloads\\Aariz (1)\\Aariz\\Annotations\"\n",
    "output_dir = \"Aariz Dataset Annotated\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Specific files to process\n",
    "files_to_process = [\n",
    "    'cks2ip8g62b6r0yuf65bga4sa',\n",
    "    'cl5lg05ue018y074kdq6yc9cj',\n",
    "    'cl5lg05ur01lu074kexxr1ofb',\n",
    "    'cl6cc2n5i401f0771as4t0pmi',\n",
    "    'cl7wxu5n5agfg077naial22ae'\n",
    "]\n",
    "\n",
    "for base_name in files_to_process:\n",
    "    # Try to find image with various extensions\n",
    "    image_extensions = ['.bmp', '.jpg', '.jpeg', '.png', '.tif', '.tiff', '.BMP', '.JPG', '.PNG']\n",
    "    img = None\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_path = f\"{image_dir}\\\\{base_name}{ext}\"\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                print(f\"Processing: {base_name}{ext}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Warning: No image found for {base_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Load annotations\n",
    "    try:\n",
    "        with open(f\"{annotation_dir}\\\\{base_name}.json\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: No annotation file found for {base_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"{base_name}\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Plot landmarks\n",
    "    for landmark in data['landmarks']:\n",
    "        x, y = landmark['value']['x'], landmark['value']['y']\n",
    "        ax.plot(x, y, 'r.', markersize=4)\n",
    "        ax.text(x+10, y-10, landmark['symbol'], color='yellow', \n",
    "                fontsize=7, weight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.7))\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(f\"{output_dir}\\\\annotated_{base_name}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved: annotated_{base_name}.png\")\n",
    "\n",
    "print(f\"\\nAll images saved to '{output_dir}' folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99923703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Final Corrections to PKU Dataset...\n",
      "==================================================\n",
      "\n",
      "Processing doctor1: 102 files\n",
      "âœ“ Fixed 102 annotation files in doctor1\n",
      "\n",
      "Processing doctor2: 102 files\n",
      "âœ“ Fixed 102 annotation files in doctor2\n",
      "\n",
      "==================================================\n",
      "âœ… Final corrections complete!\n",
      "ðŸ“ Dataset updated in place: PKU_Dataset_Corrected\n",
      "\n",
      "Final corrections applied:\n",
      "------------------------------\n",
      "  â€¢ Leftmost B â†’ Go (Gonion)\n",
      "  â€¢ Leftmost Pos â†’ Pog (Pogonion)\n",
      "  â€¢ Ls â†” Li (swapped)\n",
      "\n",
      "Verifying corrections with first annotation file...\n",
      "Landmarks in 1.json: S, N, Or, Po, A, B, Pog, Me, Gn, Go, LIT, UIT, Ls, Li, Sn, Pos, PNS, ANS, Ar\n",
      "âœ“ No duplicate landmarks found!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset paths\n",
    "corrected_dir = \"PKU_Dataset_Corrected\"\n",
    "\n",
    "def fix_duplicates_and_swap(landmarks):\n",
    "    \"\"\"Fix duplicate B and Pos landmarks, and swap Ls/Li\"\"\"\n",
    "    \n",
    "    # Find all B landmarks and their positions\n",
    "    b_landmarks = [(i, l) for i, l in enumerate(landmarks) if l['symbol'] == 'B']\n",
    "    if len(b_landmarks) == 2:\n",
    "        # Find the leftmost B (smallest x value)\n",
    "        b_landmarks.sort(key=lambda x: x[1]['value']['x'])\n",
    "        leftmost_b_idx = b_landmarks[0][0]\n",
    "        # Change leftmost B to Go\n",
    "        landmarks[leftmost_b_idx]['symbol'] = 'Go'\n",
    "        landmarks[leftmost_b_idx]['title'] = 'Gonion'\n",
    "    \n",
    "    # Find all Pos landmarks and their positions\n",
    "    pos_landmarks = [(i, l) for i, l in enumerate(landmarks) if l['symbol'] == 'Pos']\n",
    "    if len(pos_landmarks) == 2:\n",
    "        # Find the leftmost Pos (smallest x value)\n",
    "        pos_landmarks.sort(key=lambda x: x[1]['value']['x'])\n",
    "        leftmost_pos_idx = pos_landmarks[0][0]\n",
    "        # Change leftmost Pos to Pog\n",
    "        landmarks[leftmost_pos_idx]['symbol'] = 'Pog'\n",
    "        landmarks[leftmost_pos_idx]['title'] = 'Pogonion'\n",
    "    \n",
    "    # Swap Ls and Li\n",
    "    for landmark in landmarks:\n",
    "        if landmark['symbol'] == 'Ls':\n",
    "            landmark['symbol'] = 'Li'\n",
    "            landmark['title'] = 'Labrale inferius'\n",
    "        elif landmark['symbol'] == 'Li':\n",
    "            landmark['symbol'] = 'Ls'\n",
    "            landmark['title'] = 'Labrale superius'\n",
    "    \n",
    "    return landmarks\n",
    "\n",
    "def process_annotation_folder(folder_name):\n",
    "    \"\"\"Process all JSON files in a doctor folder\"\"\"\n",
    "    folder_path = os.path.join(corrected_dir, folder_name)\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} not found, skipping...\")\n",
    "        return\n",
    "    \n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    print(f\"\\nProcessing {folder_name}: {len(json_files)} files\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        file_path = os.path.join(folder_path, json_file)\n",
    "        \n",
    "        # Load JSON\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Fix duplicates and swap Ls/Li\n",
    "        data['landmarks'] = fix_duplicates_and_swap(data['landmarks'])\n",
    "        \n",
    "        # Save corrected JSON (overwrite)\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ“ Fixed {len(json_files)} annotation files in {folder_name}\")\n",
    "\n",
    "# Apply final corrections\n",
    "print(\"Applying Final Corrections to PKU Dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Process doctor1 annotations\n",
    "process_annotation_folder('doctor1')\n",
    "\n",
    "# Process doctor2 annotations\n",
    "process_annotation_folder('doctor2')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"âœ… Final corrections complete!\")\n",
    "print(f\"ðŸ“ Dataset updated in place: {corrected_dir}\")\n",
    "print(\"\\nFinal corrections applied:\")\n",
    "print(\"-\"*30)\n",
    "print(\"  â€¢ Leftmost B â†’ Go (Gonion)\")\n",
    "print(\"  â€¢ Leftmost Pos â†’ Pog (Pogonion)\")\n",
    "print(\"  â€¢ Ls â†” Li (swapped)\")\n",
    "\n",
    "# Verify the corrections by showing a sample\n",
    "print(\"\\nVerifying corrections with first annotation file...\")\n",
    "sample_folder = os.path.join(corrected_dir, 'doctor1')\n",
    "if os.path.exists(sample_folder):\n",
    "    json_files = [f for f in os.listdir(sample_folder) if f.endswith('.json')]\n",
    "    if json_files:\n",
    "        with open(os.path.join(sample_folder, json_files[0]), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            symbols = [l['symbol'] for l in data['landmarks']]\n",
    "            print(f\"Landmarks in {json_files[0]}: {', '.join(symbols)}\")\n",
    "            \n",
    "            # Check for duplicates\n",
    "            from collections import Counter\n",
    "            counts = Counter(symbols)\n",
    "            duplicates = [symbol for symbol, count in counts.items() if count > 1]\n",
    "            if duplicates:\n",
    "                print(f\"âš  Warning: Still have duplicates: {duplicates}\")\n",
    "            else:\n",
    "                print(\"âœ“ No duplicate landmarks found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
